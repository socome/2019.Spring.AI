{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VLADNet_jwkim.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/socome/2019.Spring.AI/blob/master/VLADNet_jwkim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVFa5HXlsEK1",
        "colab_type": "code",
        "outputId": "b64e8028-a308-4714-836b-2825dad2ae63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqsULtEewAJy",
        "colab_type": "code",
        "outputId": "28d48e7e-130b-4d9d-f3bd-f48a94509b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if os.path.exists('/content/gdrive')==False:\n",
        "    drive.mount('/content/gdrive')\n",
        "    print('Google Drive is mounted\\n')\n",
        "else:\n",
        "    print('Google Drive is already mounted\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Google Drive is mounted\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuJUd_WDw8SB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_lists = os.listdir(os.path.join('./gdrive/My Drive/AILeader_Dataset/세종대 정문/'))\n",
        "image_lists.sort()\n",
        "\n",
        "img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/세종대 정문/',image_lists[0]), target_size=(128, 128))\n",
        "img = image.img_to_array(img)\n",
        "img = img.reshape((3,128,128))\n",
        "List_door = np.array(img)\n",
        "List_door = List_door[np.newaxis, :, :, :]\n",
        "\n",
        "for ii, image_list in enumerate(image_lists): \n",
        "  if ii is not 0 :\n",
        "    img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/세종대 정문/',image_list), target_size=(128, 128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x.reshape((3,128,128))\n",
        "    x = x[np.newaxis, :, :, :]\n",
        "    List_door = np.concatenate((List_door, x))\n",
        "\n",
        "np.save('./gdrive/My Drive/AILeader_Dataset/세종대정문',List_door)\n",
        "    \n",
        "List_door.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPdFu6oe4X6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_lists = os.listdir(os.path.join('./gdrive/My Drive/AILeader_Dataset/어린이대공원정문/'))\n",
        "image_lists.sort()\n",
        "\n",
        "img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/어린이대공원정문/',image_lists[0]), target_size=(128, 128))\n",
        "img = image.img_to_array(img)\n",
        "img = img.reshape((3,128,128))\n",
        "List_C_door = np.array(img)\n",
        "List_C_door = List_C_door[np.newaxis, :, :, :]\n",
        "\n",
        "for ii, image_list in enumerate(image_lists): \n",
        "  if ii is not 0 :\n",
        "    img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/어린이대공원정문/',image_list), target_size=(128, 128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x.reshape((3,128,128))\n",
        "    x = x[np.newaxis, :, :, :]\n",
        "    List_C_door = np.concatenate((List_C_door, x))\n",
        "\n",
        "np.save('./gdrive/My Drive/AILeader_Dataset/어린이대공원정문',List_C_door)\n",
        "    \n",
        "List_C_door.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTKbu6Kq6m0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_lists = os.listdir(os.path.join('./gdrive/My Drive/AILeader_Dataset/대양AI센터/'))\n",
        "image_lists.sort()\n",
        "\n",
        "img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/대양AI센터/',image_lists[0]), target_size=(128, 128))\n",
        "img = image.img_to_array(img)\n",
        "img = img.reshape((3,128,128))\n",
        "AI_center = np.array(img)\n",
        "AI_center = AI_center[np.newaxis, :, :, :]\n",
        "\n",
        "for ii, image_list in enumerate(image_lists): \n",
        "  if ii is not 0 :\n",
        "    img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/대양AI센터/',image_list), target_size=(128, 128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x.reshape((3,128,128))\n",
        "    x = x[np.newaxis, :, :, :]\n",
        "    AI_center = np.concatenate((AI_center, x))\n",
        "\n",
        "np.save('./gdrive/My Drive/AILeader_Dataset/대양AI센터',AI_center)\n",
        "    \n",
        "AI_center.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sz0gKiQJlm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_lists = os.listdir(os.path.join('./gdrive/My Drive/AILeader_Dataset/세종대 시계탑/'))\n",
        "image_lists.sort()\n",
        "\n",
        "img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/세종대 시계탑/',image_lists[0]), target_size=(128, 128))\n",
        "img = image.img_to_array(img)\n",
        "img = img.reshape((3,128,128))\n",
        "C_Tower = np.array(img)\n",
        "C_Tower = C_Tower[np.newaxis, :, :, :]\n",
        "\n",
        "for ii, image_list in enumerate(image_lists): \n",
        "  if ii is not 0 :\n",
        "    img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/세종대 시계탑/',image_list), target_size=(128, 128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x.reshape((3,128,128))\n",
        "    x = x[np.newaxis, :, :, :]\n",
        "    C_Tower = np.concatenate((C_Tower, x))\n",
        "\n",
        "np.save('./gdrive/My Drive/AILeader_Dataset/세종대 시계탑',C_Tower)\n",
        "    \n",
        "C_Tower.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goGEviVHKPxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_lists = os.listdir(os.path.join('./gdrive/My Drive/AILeader_Dataset/박물관/'))\n",
        "image_lists.sort()\n",
        "\n",
        "img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/박물관/',image_lists[0]), target_size=(128, 128))\n",
        "img = image.img_to_array(img)\n",
        "img = img.reshape((3,128,128))\n",
        "\n",
        "Museum = np.array(img)\n",
        "Museum = Museum[np.newaxis, :, :, :]\n",
        "\n",
        "for ii, image_list in enumerate(image_lists): \n",
        "  if ii is not 0 :\n",
        "    img = image.load_img(os.path.join('./gdrive/My Drive/AILeader_Dataset/박물관/',image_list), target_size=(128, 128))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x.reshape((3,128,128))\n",
        "    x = x[np.newaxis, :, :, :]\n",
        "    Museum = np.concatenate((Museum, x))\n",
        "\n",
        "\n",
        "np.save('./gdrive/My Drive/AILeader_Dataset/박물관',Museum)\n",
        "    \n",
        "Museum.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrfD-ILt-2BN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "List_C_door = np.load('./gdrive/My Drive/AILeader_Dataset/어린이대공원정문.npy')\n",
        "List_door = np.load('./gdrive/My Drive/AILeader_Dataset/세종대정문.npy')\n",
        "AI_center = np.load('./gdrive/My Drive/AILeader_Dataset/대양AI센터.npy')\n",
        "Museum = np.load('./gdrive/My Drive/AILeader_Dataset/박물관.npy')\n",
        "C_Tower = np.load('./gdrive/My Drive/AILeader_Dataset/세종대 시계탑.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ByNd9eMsFYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetVLAD(nn.Module):\n",
        "    \"\"\"NetVLAD layer implementation\"\"\"\n",
        "\n",
        "    def __init__(self, num_clusters=64, dim=128, alpha=100.0,\n",
        "                 normalize_input=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_clusters : int\n",
        "                The number of clusters\n",
        "            dim : int\n",
        "                Dimension of descriptors\n",
        "            alpha : float\n",
        "                Parameter of initialization. Larger value is harder assignment.\n",
        "            normalize_input : bool\n",
        "                If true, descriptor-wise L2 normalization is applied to input.\n",
        "        \"\"\"\n",
        "        super(NetVLAD, self).__init__()\n",
        "        self.num_clusters = num_clusters\n",
        "        self.dim = dim\n",
        "        self.alpha = alpha\n",
        "        self.normalize_input = normalize_input\n",
        "        self.conv = nn.Conv2d(dim, num_clusters, kernel_size=(1, 1), bias=True)\n",
        "        self.centroids = nn.Parameter(torch.rand(num_clusters, dim))\n",
        "        self._init_params()\n",
        "\n",
        "    def _init_params(self):\n",
        "        self.conv.weight = nn.Parameter(\n",
        "            (2.0 * self.alpha * self.centroids).unsqueeze(-1).unsqueeze(-1)\n",
        "        )\n",
        "        self.conv.bias = nn.Parameter(\n",
        "            - self.alpha * self.centroids.norm(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C = x.shape[:2]\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = F.normalize(x, p=2, dim=1)  # across descriptor dim\n",
        "\n",
        "        # soft-assignment\n",
        "        soft_assign = self.conv(x).view(N, self.num_clusters, -1)\n",
        "        soft_assign = F.softmax(soft_assign, dim=1)\n",
        "\n",
        "        x_flatten = x.view(N, C, -1)\n",
        "        \n",
        "        # calculate residuals to each clusters\n",
        "        residual = x_flatten.expand(self.num_clusters, -1, -1, -1).permute(1, 0, 2, 3) - \\\n",
        "            self.centroids.expand(x_flatten.size(-1), -1, -1).permute(1, 2, 0).unsqueeze(0)\n",
        "        residual *= soft_assign.unsqueeze(2)\n",
        "        vlad = residual.sum(dim=-1)\n",
        "\n",
        "        vlad = F.normalize(vlad, p=2, dim=2)  # intra-normalization\n",
        "        vlad = vlad.view(x.size(0), -1)  # flatten\n",
        "        vlad = F.normalize(vlad, p=2, dim=1)  # L2 normalize\n",
        "\n",
        "        return vlad\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKzKKFWksfVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbedNet(nn.Module):\n",
        "    def __init__(self, base_model, net_vlad):\n",
        "        super(EmbedNet, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.net_vlad = net_vlad\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        embedded_x = self.net_vlad(x)\n",
        "        return embedded_x\n",
        "      \n",
        "class TripletNet(nn.Module):\n",
        "    def __init__(self, embed_net):\n",
        "        super(TripletNet, self).__init__()\n",
        "        self.embed_net = embed_net\n",
        "\n",
        "    def forward(self, a, p, n):\n",
        "        embedded_a = self.embed_net(a)\n",
        "        embedded_p = self.embed_net(p)\n",
        "        embedded_n = self.embed_net(n)\n",
        "        return embedded_a, embedded_p, embedded_n\n",
        "\n",
        "    def feature_extract(self, x):\n",
        "        return self.embed_net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD_yKdlMsZai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HardTripletLoss(nn.Module):\n",
        "    \"\"\"Hard/Hardest Triplet Loss\n",
        "    (pytorch implementation of https://omoindrot.github.io/triplet-loss)\n",
        "    For each anchor, we get the hardest positive and hardest negative to form a triplet.\n",
        "    \"\"\"\n",
        "    def __init__(self, margin=0.1, hardest=False, squared=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            margin: margin for triplet loss\n",
        "            hardest: If true, loss is considered only hardest triplets.\n",
        "            squared: If true, output is the pairwise squared euclidean distance matrix.\n",
        "                If false, output is the pairwise euclidean distance matrix.\n",
        "        \"\"\"\n",
        "        super(HardTripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        self.hardest = hardest\n",
        "        self.squared = squared\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            labels: labels of the batch, of size (batch_size,)\n",
        "            embeddings: tensor of shape (batch_size, embed_dim)\n",
        "        Returns:\n",
        "            triplet_loss: scalar tensor containing the triplet loss\n",
        "        \"\"\"\n",
        "        pairwise_dist = _pairwise_distance(embeddings, squared=self.squared)\n",
        "\n",
        "        if self.hardest:\n",
        "            # Get the hardest positive pairs\n",
        "            mask_anchor_positive = _get_anchor_positive_triplet_mask(labels).float()\n",
        "            valid_positive_dist = pairwise_dist * mask_anchor_positive\n",
        "            hardest_positive_dist, _ = torch.max(valid_positive_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Get the hardest negative pairs\n",
        "            mask_anchor_negative = _get_anchor_negative_triplet_mask(labels).float()\n",
        "            max_anchor_negative_dist, _ = torch.max(pairwise_dist, dim=1, keepdim=True)\n",
        "            anchor_negative_dist = pairwise_dist + max_anchor_negative_dist * (\n",
        "                    1.0 - mask_anchor_negative)\n",
        "            hardest_negative_dist, _ = torch.min(anchor_negative_dist, dim=1, keepdim=True)\n",
        "\n",
        "            # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
        "            triplet_loss = F.relu(hardest_positive_dist - hardest_negative_dist + 0.1)\n",
        "            triplet_loss = torch.mean(triplet_loss)\n",
        "        else:\n",
        "            anc_pos_dist = pairwise_dist.unsqueeze(dim=2)\n",
        "            anc_neg_dist = pairwise_dist.unsqueeze(dim=1)\n",
        "\n",
        "            # Compute a 3D tensor of size (batch_size, batch_size, batch_size)\n",
        "            # triplet_loss[i, j, k] will contain the triplet loss of anc=i, pos=j, neg=k\n",
        "            # Uses broadcasting where the 1st argument has shape (batch_size, batch_size, 1)\n",
        "            # and the 2nd (batch_size, 1, batch_size)\n",
        "            loss = anc_pos_dist - anc_neg_dist + self.margin\n",
        "\n",
        "            mask = _get_triplet_mask(labels).float()\n",
        "            triplet_loss = loss * mask\n",
        "\n",
        "            # Remove negative losses (i.e. the easy triplets)\n",
        "            triplet_loss = F.relu(triplet_loss)\n",
        "\n",
        "            # Count number of hard triplets (where triplet_loss > 0)\n",
        "            hard_triplets = torch.gt(triplet_loss, 1e-16).float()\n",
        "            num_hard_triplets = torch.sum(hard_triplets)\n",
        "\n",
        "            triplet_loss = torch.sum(triplet_loss) / (num_hard_triplets + 1e-16)\n",
        "\n",
        "        return triplet_loss\n",
        "\n",
        "\n",
        "def _pairwise_distance(x, squared=False, eps=1e-16):\n",
        "    # Compute the 2D matrix of distances between all the embeddings.\n",
        "\n",
        "    cor_mat = torch.matmul(x, x.t())\n",
        "    norm_mat = cor_mat.diag()\n",
        "    distances = norm_mat.unsqueeze(1) - 2 * cor_mat + norm_mat.unsqueeze(0)\n",
        "    distances = F.relu(distances)\n",
        "\n",
        "    if not squared:\n",
        "        mask = torch.eq(distances, 0.0).float()\n",
        "        distances = distances + mask * eps\n",
        "        distances = torch.sqrt(distances)\n",
        "        distances = distances * (1.0 - mask)\n",
        "\n",
        "    return distances\n",
        "\n",
        "\n",
        "def _get_anchor_positive_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, p] is True iff a and p are distinct and have same label.\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    indices_not_equal = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "\n",
        "    # Check if labels[i] == labels[j]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "\n",
        "    mask = indices_not_equal * labels_equal\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_anchor_negative_triplet_mask(labels):\n",
        "    # Return a 2D mask where mask[a, n] is True iff a and n have distinct labels.\n",
        "\n",
        "    # Check if labels[i] != labels[k]\n",
        "    labels_equal = torch.unsqueeze(labels, 0) == torch.unsqueeze(labels, 1)\n",
        "    mask = labels_equal ^ 1\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def _get_triplet_mask(labels):\n",
        "    \"\"\"Return a 3D mask where mask[a, p, n] is True iff the triplet (a, p, n) is valid.\n",
        "    A triplet (i, j, k) is valid if:\n",
        "        - i, j, k are distinct\n",
        "        - labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Check that i, j and k are distinct\n",
        "    indices_not_same = torch.eye(labels.shape[0]).to(device).byte() ^ 1\n",
        "    i_not_equal_j = torch.unsqueeze(indices_not_same, 2)\n",
        "    i_not_equal_k = torch.unsqueeze(indices_not_same, 1)\n",
        "    j_not_equal_k = torch.unsqueeze(indices_not_same, 0)\n",
        "    distinct_indices = i_not_equal_j * i_not_equal_k * j_not_equal_k\n",
        "\n",
        "    # Check if labels[i] == labels[j] and labels[i] != labels[k]\n",
        "    label_equal = torch.eq(torch.unsqueeze(labels, 0), torch.unsqueeze(labels, 1))\n",
        "    i_equal_j = torch.unsqueeze(label_equal, 2)\n",
        "    i_equal_k = torch.unsqueeze(label_equal, 1)\n",
        "    valid_labels = i_equal_j * (i_equal_k ^ 1)\n",
        "\n",
        "    mask = distinct_indices * valid_labels   # Combine the two masks\n",
        "\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPT97DFbsK7w",
        "colab_type": "code",
        "outputId": "1c4c31a4-e874-444b-a7f9-540ebb789a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Discard layers at the end of base network\n",
        "encoder = resnet18(pretrained=True)\n",
        "base_model = nn.Sequential(\n",
        "    encoder.conv1,\n",
        "    encoder.bn1,\n",
        "    encoder.relu,\n",
        "    encoder.maxpool,\n",
        "    encoder.layer1,\n",
        "    encoder.layer2,\n",
        "    encoder.layer3,\n",
        "    encoder.layer4,\n",
        ")\n",
        "dim = list(base_model.parameters())[-1].shape[0]  # last channels (512)\n",
        "\n",
        "# Define model for embedding\n",
        "net_vlad = NetVLAD(num_clusters=32, dim=dim, alpha=1.0)\n",
        "model = EmbedNet(base_model, net_vlad).cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 46827520/46827520 [00:01<00:00, 28387171.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxHsPHtrsp4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss\n",
        "criterion = HardTripletLoss(margin=0.1).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUphLuCaLMuT",
        "colab_type": "code",
        "outputId": "aab47b5e-e0ed-450a-b20b-cc99fe06e128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(List_door.shape,List_C_door.shape,AI_center.shape,Museum.shape,C_Tower.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(98, 3, 128, 128) (170, 3, 128, 128) (184, 3, 128, 128) (110, 3, 128, 128) (109, 3, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1_C2i2l7cV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_set = np.concatenate((List_door[:80], List_C_door[:80],AI_center[:80],Museum[:80],C_Tower[:80]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejgb_fHl7z-D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_set = torch.from_numpy(train_image_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx6ujJbm8vxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_set = train_image_set.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ji9rrNN8-8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_train = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "                  1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
        "                  2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,\n",
        "                  3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,\n",
        "                  4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwaU5pM59N_9",
        "colab_type": "code",
        "outputId": "599d5df0-0b75-402b-94d6-4f73d747116e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "label_train = torch.from_numpy(label_train)\n",
        "label_train = label_train.cuda()\n",
        "label_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([400])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJkRFjLlMEcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 70\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQPFdi7QL-uH",
        "colab_type": "code",
        "outputId": "8db4c3ad-cbdd-4a68-c572-dd3e60d183ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1277
        }
      },
      "source": [
        "for ii in range(epoch):\n",
        "  output_train = model(train_image_set)\n",
        "  triplet_loss = criterion(output_train, label_train)\n",
        "  optimizer.zero_grad()\n",
        "  triplet_loss.backward(retain_graph=True)\n",
        "  optimizer.step()\n",
        "  \n",
        "  print(ii,triplet_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "1 tensor(0.0982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "2 tensor(0.0981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "3 tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "4 tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "5 tensor(0.0977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "6 tensor(0.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "7 tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "8 tensor(0.0972, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "9 tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "10 tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "11 tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "12 tensor(0.0964, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "13 tensor(0.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "14 tensor(0.0959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "15 tensor(0.0956, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "16 tensor(0.0953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "17 tensor(0.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "18 tensor(0.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "19 tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "20 tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "21 tensor(0.0935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "22 tensor(0.0931, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "23 tensor(0.0927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "24 tensor(0.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "25 tensor(0.0917, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "26 tensor(0.0912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "27 tensor(0.0906, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "28 tensor(0.0900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "29 tensor(0.0893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "30 tensor(0.0887, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "31 tensor(0.0879, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "32 tensor(0.0871, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "33 tensor(0.0863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "34 tensor(0.0855, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "35 tensor(0.0844, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "36 tensor(0.0835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "37 tensor(0.0823, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "38 tensor(0.0813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "39 tensor(0.0799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "40 tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "41 tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "42 tensor(0.0752, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "43 tensor(0.0730, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "44 tensor(0.0709, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "45 tensor(0.0682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "46 tensor(0.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "47 tensor(0.0618, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "48 tensor(0.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "49 tensor(0.0535, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "50 tensor(0.0499, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "51 tensor(0.0464, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "52 tensor(0.0426, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "53 tensor(0.0388, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "54 tensor(0.0363, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "55 tensor(0.0316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "56 tensor(0.0303, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "57 tensor(0.0258, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "58 tensor(0.0227, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "59 tensor(0.0204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "60 tensor(0.0184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "61 tensor(0.0174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "62 tensor(0.0184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "63 tensor(0.0131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "64 tensor(0.0120, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "65 tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "66 tensor(0.0102, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "67 tensor(0.0105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "68 tensor(0.0076, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "69 tensor(0.0068, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0kw_RpmQbV_",
        "colab_type": "code",
        "outputId": "c564159d-5bb4-4315-c68f-edb1d58ae851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test_image_set = np.concatenate((List_door[-15:], List_C_door[-15:],AI_center[-15:],Museum[-15:],C_Tower[-15:]))\n",
        "test_image_set = torch.from_numpy(test_image_set)\n",
        "test_image_set = test_image_set.cuda()\n",
        "print(List_door[-15:].shape,List_C_door[-15:].shape,AI_center[-15:].shape,Museum[-15:].shape,C_Tower[-15:].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15, 3, 128, 128) (15, 3, 128, 128) (15, 3, 128, 128) (15, 3, 128, 128) (15, 3, 128, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HdKVqIVQmbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,\n",
        "                  1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
        "                  2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,\n",
        "                  3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,\n",
        "                  4,4,4,4,4,4,4,4,4,4,4,4,4,4,4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxt_tbGkT3KA",
        "colab_type": "code",
        "outputId": "32bf058b-e2b9-403e-bbac-0127b3ca49c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# label_test = torch.from_numpy(label_test)\n",
        "# label_test = label_test.cuda()\n",
        "label_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([75])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-SC7xaGMYJm",
        "colab_type": "code",
        "outputId": "468a01b8-3540-4dfa-b6f1-348d195ccaf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "output_test = model(test_image_set)\n",
        "output_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([75, 16384])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD7yhbTHOmj9",
        "colab_type": "code",
        "outputId": "2fc0ec15-9a9f-4e08-9038-536dc3d15ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets, metrics\n",
        "\n",
        "X = output_train.cpu().data.numpy()\n",
        "Y = label_train.cpu().data.numpy()\n",
        "\n",
        "clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
        "clf.fit(X, Y) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRL85iOzUQu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = output_test.cpu().data.numpy()\n",
        "Y_test = label_test.cpu().data.numpy()\n",
        "\n",
        "pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxogKchJZDZM",
        "colab_type": "code",
        "outputId": "2f1516be-7721-49c2-8865-dc1231270a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "print(metrics.classification_report(Y_test,pred))\n",
        "print(metrics.confusion_matrix(Y_test,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.80      0.86        15\n",
            "           1       0.80      0.80      0.80        15\n",
            "           2       0.71      0.80      0.75        15\n",
            "           3       0.58      0.73      0.65        15\n",
            "           4       0.55      0.40      0.46        15\n",
            "\n",
            "    accuracy                           0.71        75\n",
            "   macro avg       0.71      0.71      0.70        75\n",
            "weighted avg       0.71      0.71      0.70        75\n",
            "\n",
            "[[12  1  0  2  0]\n",
            " [ 0 12  0  2  1]\n",
            " [ 0  1 12  0  2]\n",
            " [ 0  1  1 11  2]\n",
            " [ 1  0  4  4  6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqKcZT_-ZHTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}